{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a32b29b3e72d776b7d6dec9d59704dab568edc6"
   },
   "source": [
    "# Welcome to Exploring RNNs ðŸŽ¡ðŸŽ¢\n",
    "\n",
    "![Library](https://images.unsplash.com/photo-1530608031805-8e170c1b793a?ixlib=rb-0.3.5&ixid=eyJhcHBfaWQiOjEyMDd9&s=02e80521a07cf0cd447cf03269dee09b&auto=format&fit=crop&w=967&q=80)\n",
    "\n",
    "(Image from Unsplash, courtesy of : @jbsinger1970)\n",
    "\n",
    "## Background\n",
    "\n",
    "Recurrent Neural Networks (RNN) allow us to remember context better than regular Neural Networks. RNNs have loops in them allowing us to store information. RNNs are usually many copies of the same network passing state to the next neuron in the network.  \n",
    "\n",
    "In this notebook we are going to try and predict the next character after it has been trained on a text corpus. We will use the Fast.ai Library along with Pytorch to achieve this.  \n",
    "\n",
    "# Table of Contents:\n",
    "\n",
    "* Import data and libraries\n",
    "* EDA\n",
    "* Training Models\n",
    "\n",
    "## Resouces Used to create the content in this notebook:\n",
    "\n",
    "* Fast.ai Lesson 6\n",
    "* [NLP Beginner's Tutorial using NLTK](https://www.kaggle.com/pavansanagapati/nlp-beginner-s-tutorial-using-nltk)\n",
    "* [Recurrent Neural Network - The Math of Intelligence (Week 5)](https://youtu.be/BwmddtPFWtA)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a71b943dec92f82d054dfd8e3f54edb161472bd0"
   },
   "source": [
    "# Import data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-def8c99d3617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[0;31m# linear algebra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m \u001b[0;31m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "\n",
    "from fastai.column_data import *\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "Lets go ahead and set a path for our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "9160b64dd9cde17f8d63494837b8cbdb02d6b155"
   },
   "outputs": [],
   "source": [
    "PATH = 'data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "fe2b1e7919214af08a06c634a7773cc300d4e113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus lenght: 214602\n"
     ]
    }
   ],
   "source": [
    "doc = open(f'{PATH}THOR RAGNAROK.txt').read()\n",
    "print('corpus lenght:', len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec6e3e391d205d9b8476f44a04eb14984a0c80a9"
   },
   "outputs": [],
   "source": [
    "doc[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "09c149c644d8f1ecab7f724a0817de0b15079a43"
   },
   "source": [
    "Lets get the `vocab_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7d903518eb5f76ad4fa58192766d3b3ac49f2963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 82\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(doc)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "a0cb1f5cdcd51eb9b675d8459dede9480a6a007b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t\\n !\"#&\\'()+,-./0123456789:?ABCDEFGHIJKLMNOPQRSTUVWXYZ`abcdefghijklmnopqrstu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars.insert(0,\"\\0\")\n",
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "0285601cc7b8b3867d4bbd94af7e65877af02c22"
   },
   "outputs": [],
   "source": [
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0485dc3b4a3a63d1dfea498e7e3123fb2a83c799"
   },
   "source": [
    "Each of the integers below represent a character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "5c86748f50754c03cc5da28b6279cad448ccd53c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 46,\n",
       " 34,\n",
       " 41,\n",
       " 44,\n",
       " 25,\n",
       " 2,\n",
       " 44,\n",
       " 27,\n",
       " 33,\n",
       " 40,\n",
       " 27,\n",
       " 44,\n",
       " 41,\n",
       " 37,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 49,\n",
       " 71,\n",
       " 62,\n",
       " 73,\n",
       " 73,\n",
       " 58,\n",
       " 67,\n",
       " 2,\n",
       " 55,\n",
       " 78,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 31,\n",
       " 71,\n",
       " 62,\n",
       " 56,\n",
       " 2,\n",
       " 42,\n",
       " 58,\n",
       " 54,\n",
       " 71,\n",
       " 72,\n",
       " 68,\n",
       " 67,\n",
       " 2,\n",
       " 54,\n",
       " 67,\n",
       " 57,\n",
       " 2,\n",
       " 29,\n",
       " 71,\n",
       " 54,\n",
       " 62,\n",
       " 60,\n",
       " 2,\n",
       " 37,\n",
       " 78,\n",
       " 65,\n",
       " 58,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 29,\n",
       " 61,\n",
       " 71,\n",
       " 62,\n",
       " 72,\n",
       " 73,\n",
       " 68,\n",
       " 69,\n",
       " 61,\n",
       " 58,\n",
       " 71,\n",
       " 2,\n",
       " 38,\n",
       " 13,\n",
       " 2,\n",
       " 51,\n",
       " 68,\n",
       " 72,\n",
       " 73,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 16,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 41,\n",
       " 39,\n",
       " 35,\n",
       " 46,\n",
       " 46,\n",
       " 31,\n",
       " 30,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 27,\n",
       " 17,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 41,\n",
       " 39,\n",
       " 35,\n",
       " 46,\n",
       " 46,\n",
       " 31,\n",
       " 30,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 27,\n",
       " 17,\n",
       " 1,\n",
       " 1,\n",
       " 27,\n",
       " 18,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 46,\n",
       " 34,\n",
       " 31,\n",
       " 2,\n",
       " 39,\n",
       " 27,\n",
       " 44,\n",
       " 48,\n",
       " 31,\n",
       " 38,\n",
       " 2,\n",
       " 38,\n",
       " 41,\n",
       " 33,\n",
       " 41,\n",
       " 13,\n",
       " 2,\n",
       " 45,\n",
       " 39,\n",
       " 41,\n",
       " 38,\n",
       " 30,\n",
       " 31,\n",
       " 44,\n",
       " 35,\n",
       " 40,\n",
       " 33,\n",
       " 11,\n",
       " 2,\n",
       " 28,\n",
       " 31,\n",
       " 33,\n",
       " 35,\n",
       " 40,\n",
       " 40,\n",
       " 35,\n",
       " 40,\n",
       " 33,\n",
       " 2,\n",
       " 46,\n",
       " 41,\n",
       " 2,\n",
       " 46,\n",
       " 47,\n",
       " 44,\n",
       " 40,\n",
       " 2,\n",
       " 41,\n",
       " 44,\n",
       " 27,\n",
       " 40,\n",
       " 33,\n",
       " 31,\n",
       " 2,\n",
       " 35,\n",
       " 40,\n",
       " 2,\n",
       " 46,\n",
       " 34,\n",
       " 31,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 27,\n",
       " 18,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 34,\n",
       " 31,\n",
       " 27,\n",
       " 46,\n",
       " 2,\n",
       " 27,\n",
       " 45,\n",
       " 2,\n",
       " 49,\n",
       " 31,\n",
       " 2,\n",
       " 46,\n",
       " 35,\n",
       " 38,\n",
       " 46,\n",
       " 2,\n",
       " 47,\n",
       " 42,\n",
       " 2,\n",
       " 46,\n",
       " 41,\n",
       " 2,\n",
       " 45,\n",
       " 31,\n",
       " 31,\n",
       " 12,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 12,\n",
       " 32,\n",
       " 35,\n",
       " 44,\n",
       " 31,\n",
       " 13,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 40,\n",
       " 41,\n",
       " 46,\n",
       " 34,\n",
       " 35,\n",
       " 40,\n",
       " 33,\n",
       " 2,\n",
       " 28,\n",
       " 47,\n",
       " 46,\n",
       " 2,\n",
       " 32,\n",
       " 35,\n",
       " 44,\n",
       " 31,\n",
       " 13,\n",
       " 1,\n",
       " 1,\n",
       " 17,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 35,\n",
       " 40,\n",
       " 46,\n",
       " 13,\n",
       " 2,\n",
       " 46,\n",
       " 35,\n",
       " 33,\n",
       " 34,\n",
       " 46,\n",
       " 2,\n",
       " 45,\n",
       " 42,\n",
       " 27,\n",
       " 29,\n",
       " 31,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 35,\n",
       " 40,\n",
       " 30,\n",
       " 31,\n",
       " 46,\n",
       " 31,\n",
       " 44,\n",
       " 39,\n",
       " 35,\n",
       " 40,\n",
       " 27,\n",
       " 46,\n",
       " 31,\n",
       " 2,\n",
       " 46,\n",
       " 35,\n",
       " 39,\n",
       " 31,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 17,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 30,\n",
       " 54,\n",
       " 71,\n",
       " 64,\n",
       " 2,\n",
       " 54,\n",
       " 67,\n",
       " 57,\n",
       " 2,\n",
       " 56,\n",
       " 71,\n",
       " 54,\n",
       " 66,\n",
       " 69,\n",
       " 58,\n",
       " 57,\n",
       " 13,\n",
       " 2,\n",
       " 46,\n",
       " 61,\n",
       " 58,\n",
       " 2,\n",
       " 72,\n",
       " 68,\n",
       " 59,\n",
       " 73,\n",
       " 2,\n",
       " 71,\n",
       " 58,\n",
       " 57,\n",
       " 2,\n",
       " 65,\n",
       " 62,\n",
       " 60,\n",
       " 61,\n",
       " 73,\n",
       " 2,\n",
       " 68,\n",
       " 59,\n",
       " 2,\n",
       " 59,\n",
       " 62,\n",
       " 71,\n",
       " 58,\n",
       " 2,\n",
       " 72,\n",
       " 58,\n",
       " 58,\n",
       " 69,\n",
       " 72,\n",
       " 2,\n",
       " 73,\n",
       " 61,\n",
       " 71,\n",
       " 68,\n",
       " 74,\n",
       " 60,\n",
       " 61,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 62,\n",
       " 71,\n",
       " 68,\n",
       " 67,\n",
       " 2,\n",
       " 72,\n",
       " 65,\n",
       " 54,\n",
       " 73,\n",
       " 72,\n",
       " 13,\n",
       " 2,\n",
       " 35,\n",
       " 67,\n",
       " 72,\n",
       " 62,\n",
       " 57,\n",
       " 58,\n",
       " 2,\n",
       " 73,\n",
       " 61,\n",
       " 62,\n",
       " 72,\n",
       " 2,\n",
       " 56,\n",
       " 54,\n",
       " 60,\n",
       " 58,\n",
       " 2,\n",
       " 62,\n",
       " 72,\n",
       " 2,\n",
       " 54,\n",
       " 2,\n",
       " 66,\n",
       " 54,\n",
       " 67,\n",
       " 11,\n",
       " 2,\n",
       " 55,\n",
       " 68,\n",
       " 74,\n",
       " 67,\n",
       " 57,\n",
       " 2,\n",
       " 55,\n",
       " 78,\n",
       " 2,\n",
       " 56,\n",
       " 61,\n",
       " 54,\n",
       " 62,\n",
       " 67,\n",
       " 72,\n",
       " 13,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 35,\n",
       " 73,\n",
       " 7,\n",
       " 72,\n",
       " 2,\n",
       " 46,\n",
       " 34,\n",
       " 41,\n",
       " 44,\n",
       " 13,\n",
       " 2,\n",
       " 34,\n",
       " 62,\n",
       " 72,\n",
       " 2,\n",
       " 55,\n",
       " 58,\n",
       " 54,\n",
       " 71,\n",
       " 57,\n",
       " 2,\n",
       " 62,\n",
       " 72,\n",
       " 2,\n",
       " 65,\n",
       " 68,\n",
       " 67,\n",
       " 60,\n",
       " 2,\n",
       " 54,\n",
       " 67,\n",
       " 57,\n",
       " 2,\n",
       " 61,\n",
       " 62,\n",
       " 72,\n",
       " 2,\n",
       " 56,\n",
       " 65,\n",
       " 68,\n",
       " 73,\n",
       " 61,\n",
       " 58,\n",
       " 72,\n",
       " 2,\n",
       " 54,\n",
       " 71,\n",
       " 58,\n",
       " 2,\n",
       " 76,\n",
       " 68,\n",
       " 71,\n",
       " 67,\n",
       " 13,\n",
       " 2,\n",
       " 46,\n",
       " 61,\n",
       " 54,\n",
       " 73,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 71,\n",
       " 68,\n",
       " 74,\n",
       " 60,\n",
       " 61,\n",
       " 11,\n",
       " 2,\n",
       " 60,\n",
       " 71,\n",
       " 62,\n",
       " 79,\n",
       " 79,\n",
       " 65,\n",
       " 58,\n",
       " 57,\n",
       " 2,\n",
       " 65,\n",
       " 68,\n",
       " 68,\n",
       " 64,\n",
       " 2,\n",
       " 68,\n",
       " 59,\n",
       " 2,\n",
       " 54,\n",
       " 2,\n",
       " 66,\n",
       " 54,\n",
       " 67,\n",
       " 2,\n",
       " 76,\n",
       " 61,\n",
       " 68,\n",
       " 7,\n",
       " 72,\n",
       " 2,\n",
       " 72,\n",
       " 69,\n",
       " 58,\n",
       " 67,\n",
       " 73,\n",
       " 2,\n",
       " 78,\n",
       " 58,\n",
       " 54,\n",
       " 71,\n",
       " 72,\n",
       " 2,\n",
       " 68,\n",
       " 67,\n",
       " 2,\n",
       " 73,\n",
       " 61,\n",
       " 58,\n",
       " 2,\n",
       " 71,\n",
       " 68,\n",
       " 54,\n",
       " 57,\n",
       " 13,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 34,\n",
       " 58,\n",
       " 2,\n",
       " 54,\n",
       " 76,\n",
       " 54,\n",
       " 64,\n",
       " 58,\n",
       " 67,\n",
       " 72,\n",
       " 2,\n",
       " 76,\n",
       " 62,\n",
       " 73,\n",
       " 61,\n",
       " 2,\n",
       " 54,\n",
       " 2,\n",
       " 36,\n",
       " 41,\n",
       " 38,\n",
       " 46,\n",
       " 13,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 38,\n",
       " 68,\n",
       " 68,\n",
       " 64,\n",
       " 72,\n",
       " 2,\n",
       " 54,\n",
       " 71,\n",
       " 68,\n",
       " 74,\n",
       " 67,\n",
       " 57,\n",
       " 13,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 46,\n",
       " 34,\n",
       " 41,\n",
       " 44,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 40,\n",
       " 68,\n",
       " 76,\n",
       " 2,\n",
       " 35,\n",
       " 2,\n",
       " 64,\n",
       " 67,\n",
       " 68,\n",
       " 76,\n",
       " 2,\n",
       " 76,\n",
       " 61,\n",
       " 54,\n",
       " 73,\n",
       " 2,\n",
       " 78,\n",
       " 68,\n",
       " 74,\n",
       " 7,\n",
       " 71,\n",
       " 58,\n",
       " 2,\n",
       " 73,\n",
       " 61,\n",
       " 62,\n",
       " 67,\n",
       " 64,\n",
       " 62,\n",
       " 67,\n",
       " 60,\n",
       " 13,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 41,\n",
       " 61,\n",
       " 2,\n",
       " 67,\n",
       " 68,\n",
       " 3,\n",
       " 2,\n",
       " 46,\n",
       " 61,\n",
       " 68,\n",
       " 71,\n",
       " 7,\n",
       " 72,\n",
       " 2,\n",
       " 62,\n",
       " 67,\n",
       " 2,\n",
       " 54,\n",
       " 2,\n",
       " 56,\n",
       " 54,\n",
       " 60,\n",
       " 58,\n",
       " 13,\n",
       " 2,\n",
       " 34,\n",
       " 68,\n",
       " 76,\n",
       " 2,\n",
       " 57,\n",
       " 62,\n",
       " 57,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 73,\n",
       " 61,\n",
       " 62,\n",
       " 72,\n",
       " 2,\n",
       " 61,\n",
       " 54,\n",
       " 69,\n",
       " 69,\n",
       " 58,\n",
       " 67,\n",
       " 26,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [char_indices[c] for c in doc]\n",
    "idx[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "2276804a69986287c42e6bf44f61c852b73c72e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n                               THOR: RAGNAROK\\n\\n\\n\\n\\n                                 Written by\\n\\n             Eric Pearson and Craig Kyle & Christopher L. Yost\\n\\n\\n\\n\\n\\n\\n\\n 1    OMITTED                                                         1\\n\\nA2   OMITTED                                                         A2\\n\\nA3   THE MARVEL LOGO. SMOLDERING, BEGINNING TO TURN ORANGE IN THE    A3\\n     HEAT AS WE TILT UP TO SEE-\\n\\n     -FIRE.    NOTHING BUT FIRE.\\n\\n2    INT. TIGHT SPACE - INDETERMINATE TIME                           2\\n\\n     Dark and cramped. The soft red light of fire seeps through\\n     iron slats. Inside this cage is a man, bound by chains.\\n\\n     It's THOR. His beard is long and his clothes are worn. That\\n     rough, grizzled look of a man who's spent years on the road.\\n\\n     He awakens with a JOLT.   Looks around.\\n\\n                           THOR\\n                 Now I know what you're thinking.\\n                 Oh no! Thor's in a cage. How did\\n                 this happen?\\n        \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "190d9c5f352f2928e26f31a8c354ba56f6cae10a"
   },
   "source": [
    "# EDA/ Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5adadd0e51001573b977aaffe39c3904fb57f8a1"
   },
   "outputs": [],
   "source": [
    "print(sent_tokenize(doc[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2010327c6ebe0f0b15a1e995cb8bc1c10f9bb880"
   },
   "outputs": [],
   "source": [
    "print(word_tokenize(doc[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01012daff083a7b338a1cbdfdde596c62d1e38d6"
   },
   "source": [
    "# Training Models\n",
    "\n",
    "In this section we will be training quite a few models. A three Char model, a RNN with Pytorch, a stateful RNN, a GRU and LSTM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d3709468278cb44a3394bc52471df5a12008235"
   },
   "source": [
    "## Three char model\n",
    "\n",
    "![3 char](https://cdn-images-1.medium.com/max/720/1*gc1z1R1d5zHkYc75iqSWtw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "acfd259e802c9287017bf0676c0743188c24b7f2"
   },
   "source": [
    "We need to create a list of every 4th character from 0-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "813b9c773737402575784a97db0b77682e6e808f"
   },
   "outputs": [],
   "source": [
    "cs=3\n",
    "c1_dat = [idx[i] for i in range(0, len(idx)-cs,cs)]\n",
    "c2_dat = [idx[i+1] for i in range(0, len(idx)-cs,cs)]\n",
    "c3_dat = [idx[i+2] for i in range(0, len(idx)-cs,cs)]\n",
    "c4_dat = [idx[i+3] for i in range(0, len(idx)-cs,cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "e5d3b3f5ce5651fcca66eb4df00e546431e0e955"
   },
   "outputs": [],
   "source": [
    "# our inputs\n",
    "x1 = np.stack(c1_dat)\n",
    "x2 = np.stack(c2_dat)\n",
    "x3 = np.stack(c3_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "d215f8593feb5f15d409c156641e6d06459ecbb6"
   },
   "outputs": [],
   "source": [
    "#our output\n",
    "y = np.stack(c4_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a30b092880c91cec9292e9b05db968f2f7bcbd3"
   },
   "source": [
    "1st Four inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "8da01e8fb723800ae3595a1cab3045226b5fa6b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 2, 2]), array([1, 2, 2, 2]), array([1, 2, 2, 2]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4],x2[:4],x3[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "bfa285b1209dbbdf02988754a3068da65dd68b8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6bb012a38162265d701f4b5761c769bfe1b11f2"
   },
   "outputs": [],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "74c06d0ac10a7265cdf1c5b70d67403f253abea1"
   },
   "source": [
    "Lets go ahead and create our model:\n",
    "first we need to pick a size for our hidden state and the size of the embedding matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "ed6bd75594809c993cd3444f7407c0d3e9821b33"
   },
   "outputs": [],
   "source": [
    "n_hidden=256\n",
    "n_fac=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "1e0d074b6d0af4952193bd2d8616a07444a90877"
   },
   "outputs": [],
   "source": [
    "class Char3Model(nn.Module):\n",
    "    def __init__(self,vocab_size,n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size,n_fac)\n",
    "        \n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden,n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden,vocab_size)\n",
    "        \n",
    "    def forward(self,c1,c2,c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1)))\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        h = V(torch.zeros(in1.size()).cuda())\n",
    "        h = F.tanh(self.l_hidden(h+in1))\n",
    "        h = F.tanh(self.l_hidden(h+in2))\n",
    "        h = F.tanh(self.l_hidden(h+in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "568c001ef8eaa44c6bf5724311bbd0833d555ff7"
   },
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', [-1],np.stack([x1,x2,x3],axis=1), y,bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "4f82eaafc4222a086fa155ea6b1ef1fb32c866e8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Char3Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-57e246865710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChar3Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_fac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Char3Model' is not defined"
     ]
    }
   ],
   "source": [
    "m = Char3Model(vocab_size,n_fac).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "03d6894e3ec82551ed8a33fa9a264bcc0e0fcd4f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7fbbc2a9c3d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "949b7faa6d06be3ea40c5fcb6c591a1257c133b7"
   },
   "outputs": [],
   "source": [
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_uuid": "0e8c5c91a8fca04bfbcc48d38b51eea31811774c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8f63f6d6964b3b9ac595eccf04e187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.821561   3.259136  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.259136199951172]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m,md,1,opt,F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_uuid": "8ddc867710213ebe288120cc566bea1ef8937af4"
   },
   "outputs": [],
   "source": [
    "set_lrs(opt,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_uuid": "cce3230f70e3ad79ae2a22206c77e8b200396333"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4e383278634bfc9d9cff7f207fc027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.542005   2.56057   \n",
      "    1      1.481594   2.739946                              \n",
      "    2      1.437694   2.53056                               \n",
      "    3      1.415517   2.9769                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.976900100708008]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m,md,4,opt,F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5561e249bdf343a9766a1d25f63240ba43ccde4d"
   },
   "source": [
    "Lets go ahead and actually test the model by predicting the third character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "5c6c408ad7f5858c0b930685eaf765b344c02d55"
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_uuid": "a752532621b615f03c009a442ed45760274ac08a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('tho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_uuid": "e2f3cfb26ade81d74f049ba18c4d64149e835ee7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('hul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_uuid": "be0137e3f0392dd4b2ccb303ea38df484a0a5b40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('Lok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "15b8d7a8b14f4463bc8a5516deeeb9d97a618099"
   },
   "source": [
    "## RNN with Pytorch\n",
    "\n",
    "Lets go ahead create an RNN with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "8e0ca27f863c66ae9a16517a899f641f904d6f62"
   },
   "outputs": [],
   "source": [
    "class CharRnn(nn.Module):\n",
    "    def __init__(self,vocab_size,n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size,n_fac)\n",
    "        self.rnn = nn.RNN(n_fac,n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden,vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(1,bs,n_hidden))\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        outp,h = self.rnn(inp,h)\n",
    "        \n",
    "        return F.log_softmax(self.l_out(outp[-1]),dim=-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "2d4651b0bf5b6f6e079bc62f73775cc03c305c8a"
   },
   "outputs": [],
   "source": [
    "m = CharRnn(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(),1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "641a409bb49796abf7a3906d5ba6f353c4e6dd2b"
   },
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "03d1179f0a1005c4fd9186a8cd1f1c79b7f7961e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 42])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m.e(V(torch.stack(xs)))\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "2c9f7975f088ae7c010e1ffe7ff1534a6f845a98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 512, 256]), torch.Size([1, 512, 256]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = V(torch.zeros(1, 512,n_hidden))\n",
    "outp, hn = m.rnn(t,ht)\n",
    "outp.size(), hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "6f63a824efe2b279d7670a677d15b65ce449603f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 82])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m(*V(xs)); t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "c5b6bab7ae61c39ddab67422e0d6577423ef324c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3ddbde0d44408ea8a5d2e80ec35107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.138294   3.847836  \n",
      "    1      1.814901   3.196774                              \n",
      "    2      1.669055   2.99489                               \n",
      "    3      1.593262   2.648105                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.64811])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m,md,4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "da266f689098e8d0e0c2ad83c7725ad7b8c2135e"
   },
   "outputs": [],
   "source": [
    "set_lrs(opt,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "be47dfd6f18bc3c461d26618451de6d369058c4c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd947081792e493fa1d12cf348067a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.511211   2.619581  \n",
      "    1      1.502817   2.509648                              \n",
      "    2      1.49742    2.489069                              \n",
      "    3      1.490898   2.484249                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4842488765716553]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m,md,4,opt,F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "361edc7dd558df4892bd7aa775ee8b739bf5424e"
   },
   "outputs": [],
   "source": [
    "set_lrs(opt,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "e62ea33b680590e9ad0df10a710d8c58174deb94"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9287f7cb05e24ef986eeccd8733050b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.518911   2.466797  \n",
      "    1      1.515602   2.572053                              \n",
      "    2      1.494688   2.479363                              \n",
      "    3      1.493949   2.374293                              \n",
      "    4      1.492529   2.358612                              \n",
      "    5      1.485202   2.385777                              \n",
      "    6      1.479583   2.237585                              \n",
      "    7      1.470842   2.240557                              \n",
      "    8      1.461881   2.182382                              \n",
      "    9      1.465388   2.303002                              \n",
      "    10     1.456053   2.283525                              \n",
      "    11     1.450439   2.181521                              \n",
      "    12     1.437977   2.220589                              \n",
      "    13     1.442366   2.186202                              \n",
      "    14     1.435975   2.188795                              \n",
      "    15     1.424679   2.109783                              \n",
      "    16     1.417769   2.139281                              \n",
      "    17     1.419212   2.080188                              \n",
      "    18     1.409755   2.095877                              \n",
      "    19     1.408692   2.158052                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.15805])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m,md,20,opt,F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93ced1dac80acb314f94548d6284bd52fa98e114"
   },
   "source": [
    "Lets go ahead and test our model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "f398acce1f16987367729092d9c905870251e9cd"
   },
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "98b6ac2f065a9c402cf13dd88d6ab5d0bdab4195"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am thor and anden the stard a s and anden the stard a s and anden the stard a s and anden the stard a s and anden the stard a s and anden the stard a s and anden the stard a s and anden the stard a s and anden the stard a s and anden the stard a s and anden the stard a s and anden the stard a s and anden the stard a s and anden the stard a s and anden the stard a s and anden the stard a s and anden the '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('I am tho',400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stateful Model\n",
    "\n",
    "We will create a stateful model, but before that can happen we need create train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mnietzsche\u001b[0m/  THOR RAGNAROK.txt  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "9c0bf7c73e5902f57e37f5f220ed3bee08478e63"
   },
   "outputs": [],
   "source": [
    "os.makedirs(TRN, exist_ok=True)\n",
    "os.makedirs(VAL, exist_ok=True)\n",
    "\n",
    "train_perc = .8\n",
    "with open(f'{PATH}THOR RAGNAROK.txt','r') as fp:\n",
    "    lines = fp.readlines()\n",
    "    text_len = len(lines)\n",
    "    part_train = open(f'{TRN}THOR RAGNAROK1.text','w')\n",
    "    part_val = open(f'{VAL}THOR RAGNAROK2.text','w')\n",
    "    for ix,l in enumerate(lines):\n",
    "        \n",
    "        if ix/text_len<train_perc:\n",
    "            part_train.write(l)\n",
    "        else:\n",
    "            part_val.write(l)\n",
    "    part_train.close()\n",
    "    part_val.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "32774b67c99bf136cc544cff2a1a8b136eb071e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THOR RAGNAROK1.text\r\n"
     ]
    }
   ],
   "source": [
    "%ls {PATH}trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "2d98bee52e19da1d3dcd84839a3299b37bd2658c"
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True,tokenize=list)\n",
    "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH,validation=VAL_PATH,test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH,TEXT,**FILES,bs=bs,bptt=bptt,min_freq=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f5114abd6d2c080db86795112b054d43683c692"
   },
   "source": [
    "dataloader lenght, number of tokens, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "4504a5cd3ff6d177eaaf5a2bc9c239db743fb7d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " ' ',\n",
       " 'e',\n",
       " 't',\n",
       " 'o',\n",
       " 'a',\n",
       " 's',\n",
       " 'r',\n",
       " 'n',\n",
       " 'i',\n",
       " 'h',\n",
       " 'l',\n",
       " 'd',\n",
       " 'u',\n",
       " '.',\n",
       " 'g',\n",
       " 'c',\n",
       " 'm',\n",
       " 'y',\n",
       " 'f',\n",
       " 'w',\n",
       " 'k',\n",
       " 'p',\n",
       " 'b',\n",
       " ',',\n",
       " \"'\",\n",
       " 'v',\n",
       " '-',\n",
       " '!',\n",
       " '(',\n",
       " ')',\n",
       " '0',\n",
       " '?',\n",
       " '1',\n",
       " '2',\n",
       " '/',\n",
       " '6',\n",
       " 'j',\n",
       " '5',\n",
       " 'x',\n",
       " '4',\n",
       " 'z',\n",
       " ':',\n",
       " '7',\n",
       " '3',\n",
       " '\"',\n",
       " '9',\n",
       " '8',\n",
       " 'q',\n",
       " '#',\n",
       " '`']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "4936f3b20fcf022bc8c1ede9c895b21e49e74477"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function torchtext.vocab._default_unk_index()>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             ' ': 2,\n",
       "             'e': 3,\n",
       "             't': 4,\n",
       "             'o': 5,\n",
       "             'a': 6,\n",
       "             's': 7,\n",
       "             'r': 8,\n",
       "             'n': 9,\n",
       "             'i': 10,\n",
       "             'h': 11,\n",
       "             'l': 12,\n",
       "             'd': 13,\n",
       "             'u': 14,\n",
       "             '.': 15,\n",
       "             'g': 16,\n",
       "             'c': 17,\n",
       "             'm': 18,\n",
       "             'y': 19,\n",
       "             'f': 20,\n",
       "             'w': 21,\n",
       "             'k': 22,\n",
       "             'p': 23,\n",
       "             'b': 24,\n",
       "             ',': 25,\n",
       "             \"'\": 26,\n",
       "             'v': 27,\n",
       "             '-': 28,\n",
       "             '!': 29,\n",
       "             '(': 30,\n",
       "             ')': 31,\n",
       "             '0': 32,\n",
       "             '?': 33,\n",
       "             '1': 34,\n",
       "             '2': 35,\n",
       "             '/': 36,\n",
       "             '6': 37,\n",
       "             'j': 38,\n",
       "             '5': 39,\n",
       "             'x': 40,\n",
       "             '4': 41,\n",
       "             'z': 42,\n",
       "             ':': 43,\n",
       "             '7': 44,\n",
       "             '3': 45,\n",
       "             '\"': 46,\n",
       "             '9': 47,\n",
       "             '8': 48,\n",
       "             'q': 49,\n",
       "             '#': 50,\n",
       "             '`': 51,\n",
       "             '&': 0,\n",
       "             '+': 0,\n",
       "             '<eos>': 0,\n",
       "             '\\t': 0,\n",
       "             '|': 0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "TEXT.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn(nn.Module):\n",
    "    def __init__(self,vocab_size,n_fac,bs):\n",
    "        self.vocab_size = vocab_size\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac,n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden,vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self,cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs),self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp),dim=-1).view(-1,self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self,bs): self.h = V(torch.zeros(1, bs,n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn(md.nt, n_fac,512).cuda()\n",
    "opt = optim.Adam(m.parameters(),1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca72025a76f149d1b80949eb0c537851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.795493   1.75344   \n",
      "    1      1.639891   1.638164                               \n",
      "    2      1.584359   1.577129                               \n",
      "    3      1.523838   1.523816                               \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.52382])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m,md,4,opt,F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am thor aplew   ther                   sttaying..9l of her hulk somet, a dast treaminghe of on this tor banned she par.     me is loki ssipe of the valk, have deames titest meft?              chadd a lows up medhtecs trin-sastaz, on.          gadresed, is fced,.42          ifiessma of his, hat shup. ssyed soofiou have out's asgarts poces, is hulk,    ftalled!      skurge oden ouct, laukes the stalaye to\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('I am tho' ,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gated Recurrent Unit\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/720/1*_29x3zNI1C0vM3fxiIpiVA.png)\n",
    "\n",
    "from [WildML](http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulGRU(nn.Module):\n",
    "    def __init__(self,vocab_size,n_fac,bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.GRU(n_fac,n_hideen)\n",
    "        self.l_out = nn.Linear(n_hidden,vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self,cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs),self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp),dim=-1).view(-1,self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self,bs): self.h = V(torch.zeros(1,bs,n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
